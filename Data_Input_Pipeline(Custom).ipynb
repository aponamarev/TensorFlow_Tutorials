{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import threading, cv2, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a dummy lists for image files and associated annotations\n",
    "file_names = [\n",
    "    '/Users/aponamaryov/Downloads/coco_train_2014/images/COCO_train2014_000000000009.jpg',\n",
    "    '/Users/aponamaryov/Downloads/coco_train_2014/images/COCO_train2014_000000000025.jpg',\n",
    "    '/Users/aponamaryov/Downloads/coco_train_2014/images/COCO_train2014_000000000030.jpg',\n",
    "    '/Users/aponamaryov/Downloads/coco_train_2014/images/COCO_train2014_000000000034.jpg',\n",
    "    '/Users/aponamaryov/Downloads/coco_train_2014/images/COCO_train2014_000000000036.jpg',\n",
    "    '/Users/aponamaryov/Downloads/coco_train_2014/images/COCO_train2014_000000000049.jpg',\n",
    "    '/Users/aponamaryov/Downloads/coco_train_2014/images/COCO_train2014_000000000061.jpg',\n",
    "    '/Users/aponamaryov/Downloads/coco_train_2014/images/COCO_train2014_000000000064.jpg',\n",
    "    '/Users/aponamaryov/Downloads/coco_train_2014/images/COCO_train2014_000000000071.jpg',\n",
    "    '/Users/aponamaryov/Downloads/coco_train_2014/images/COCO_train2014_000000000072.jpg'\n",
    "]\n",
    "\n",
    "anns = [\n",
    "    {'bboxes': [[10.0,15.0,7.0,12.0],[12.0,17.0,9.0,14.0],[14.0,19.0,5.0,14.0]], 'labels': [1,2,1]},\n",
    "    {'bboxes': [[10.0,15.0,7.0,12.0],[12.0,17.0,9.0,14.0],[14.0,19.0,5.0,14.0]], 'labels': [2,2,1]},\n",
    "    {'bboxes': [[10.0,15.0,7.0,12.0],[12.0,17.0,9.0,14.0],[14.0,19.0,5.0,14.0]], 'labels': [3,2,1]},\n",
    "    {'bboxes': [[10.0,15.0,7.0,12.0],[12.0,17.0,9.0,14.0],[14.0,19.0,5.0,14.0]], 'labels': [4,2,1]},\n",
    "    {'bboxes': [[10.0,15.0,7.0,12.0],[12.0,17.0,9.0,14.0],[14.0,19.0,5.0,14.0]], 'labels': [5,2,1]},\n",
    "    {'bboxes': [[10.0,15.0,7.0,12.0],[12.0,17.0,9.0,14.0],[14.0,19.0,5.0,14.0]], 'labels': [6,2,1]},\n",
    "    {'bboxes': [[10.0,15.0,7.0,12.0],[12.0,17.0,9.0,14.0],[14.0,19.0,5.0,14.0]], 'labels': [7,2,1]},\n",
    "    {'bboxes': [[10.0,15.0,7.0,12.0],[12.0,17.0,9.0,14.0],[14.0,19.0,5.0,14.0]], 'labels': [8,2,1]},\n",
    "    {'bboxes': [[10.0,15.0,7.0,12.0],[12.0,17.0,9.0,14.0],[14.0,19.0,5.0,14.0]], 'labels': [9,2,1]},\n",
    "    {'bboxes': [[10.0,15.0,7.0,12.0],[12.0,17.0,9.0,14.0],[14.0,19.0,5.0,14.0]], 'labels': [10,2,1]},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resulting image shape: (640, 640, 3)\n",
      "bbox shape: 3 4\n",
      "number of labels 3\n"
     ]
    }
   ],
   "source": [
    "# Define a function that will retrieve one example\n",
    "def retrieve_example(path, annotations, size=(640,640)):\n",
    "    # 1. Check that provided path exists\n",
    "    assert os.path.exists(path), \"read method receivecd incorrect path. The following path doesn't exist {}\".\\\n",
    "        format(path)\n",
    "    # 2. Read the image\n",
    "    im = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    b, g, r = cv2.split(im)\n",
    "    im = cv2.merge([r, g, b])\n",
    "    im = cv2.resize(im, size)\n",
    "    bboxes, labels = annotations['bboxes'], annotations['labels']\n",
    "    return [im, bboxes, labels]\n",
    "\n",
    "example = retrieve_example(file_names[0], anns[0])\n",
    "print \"resulting image shape:\", example[0].shape\n",
    "print \"bbox shape:\",  len(example[1]), len(example[1][0])\n",
    "print \"number of labels\", len(example[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create placeholders for data input\n",
    "tf.reset_default_graph() # as always, reset the graph to ensure no prior run residuals will affect your script\n",
    "img_input = tf.placeholder(tf.float32, shape=[640,640,3], name='img_input')\n",
    "bbox_input = tf.placeholder(tf.float32, shape=[3,4], name='bbox_input')\n",
    "label_input = tf.placeholder(tf.int16, shape=[3], name='labels_input')\n",
    "# create a queue\n",
    "queue = tf.FIFOQueue(capacity=10, dtypes=[tf.float32, tf.float32, tf.int16],\n",
    "                    shapes=[[640,640,3], [3,4], [3]])\n",
    "# define enqueue and dequeue operations\n",
    "enqueue_inputs_op = queue.enqueue([img_input, bbox_input, label_input])\n",
    "deque_inputs_op = queue.dequeue()\n",
    "\n",
    "# define a function that will help to enqueue your inputs\n",
    "def enqueue(sess):\n",
    "    example = retrieve_example(file_names.pop(0), anns.pop(0))\n",
    "    print example[2][0]\n",
    "    sess.run(enqueue_inputs_op,\n",
    "             feed_dict={\n",
    "                 img_input: example[0],\n",
    "                 bbox_input: example[1],\n",
    "                 label_input: example[2]\n",
    "             })\n",
    "    \n",
    "# define a batch reading operation\n",
    "img_batch, bbox_batch, labels_batch = tf.train.batch(deque_inputs_op, batch_size=2, capacity=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "361\n",
      "\n",
      "\n",
      "4\n",
      "5\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "dequeued imag batch has the following shape: (2, 640, 640, 3)\n",
      "dequeued bbox batch has the following shape: (2, 3, 4)\n",
      "dequeued lables (with shape (2, 3)):\n",
      "[[2 2 1]\n",
      " [3 2 1]]\n",
      "successful execution\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # enqueue 5 examples asynchronously\n",
    "    for _ in xrange(5):\n",
    "        enqueue_example = threading.Thread(target=enqueue, args=[sess])\n",
    "        enqueue_example.isDaemon()\n",
    "        enqueue_example.start()\n",
    "    # enqueue remaining 5 examples sequentially\n",
    "    for _ in xrange(5):\n",
    "        enqueue(sess)\n",
    "    # Create a coordinator that will run a tensorflow queue\n",
    "    coord = tf.train.Coordinator()\n",
    "    # start the queue runner with the coordinator\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    img_cur_batch, bbox_cur_batch, labels_cur_batch = sess.run([img_batch, bbox_batch, labels_batch])\n",
    "    print \"dequeued imag batch has the following shape:\", img_cur_batch.shape\n",
    "    print \"dequeued bbox batch has the following shape:\", bbox_cur_batch.shape\n",
    "    print \"dequeued lables (with shape {}):\".format(labels_cur_batch.shape)\n",
    "    print labels_cur_batch\n",
    "    # once youre done, close the queue\n",
    "    queue.close(cancel_pending_enqueues=True)\n",
    "    # stop the coordinator\n",
    "    coord.request_stop()\n",
    "    # merge the result of all the threads\n",
    "    coord.join(threads)\n",
    "    \n",
    "print \"successful execution\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
